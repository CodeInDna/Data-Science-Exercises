{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e181fc1c",
   "metadata": {},
   "source": [
    "## word2vec: How to Implement word2vec\n",
    "\n",
    "### Explore Pre-trained Embeddings\n",
    "\n",
    "Some other options:\n",
    "   * glove-twitter-{25/50/100/200}\n",
    "   * glove-wiki-gigaword-{50/200/300}\n",
    "   * word2vec-google-news-300\n",
    "   * word2vec-ruscorpora-news-300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c83c10e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install gensim\n",
    "\n",
    "# !pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d07cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained word vectors using gensim\n",
    "import gensim.downloader as api\n",
    "\n",
    "wiki_embeddings = api.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc10e702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.32307 , -0.87616 ,  0.21977 ,  0.25268 ,  0.22976 ,  0.7388  ,\n",
       "       -0.37954 , -0.35307 , -0.84369 , -1.1113  , -0.30266 ,  0.33178 ,\n",
       "       -0.25113 ,  0.30448 , -0.077491, -0.89815 ,  0.092496, -1.1407  ,\n",
       "       -0.58324 ,  0.66869 , -0.23122 , -0.95855 ,  0.28262 , -0.078848,\n",
       "        0.75315 ,  0.26584 ,  0.3422  , -0.33949 ,  0.95608 ,  0.065641,\n",
       "        0.45747 ,  0.39835 ,  0.57965 ,  0.39267 , -0.21851 ,  0.58795 ,\n",
       "       -0.55999 ,  0.63368 , -0.043983, -0.68731 , -0.37841 ,  0.38026 ,\n",
       "        0.61641 , -0.88269 , -0.12346 , -0.37928 , -0.38318 ,  0.23868 ,\n",
       "        0.6685  , -0.43321 , -0.11065 ,  0.081723,  1.1569  ,  0.78958 ,\n",
       "       -0.21223 , -2.3211  , -0.67806 ,  0.44561 ,  0.65707 ,  0.1045  ,\n",
       "        0.46217 ,  0.19912 ,  0.25802 ,  0.057194,  0.53443 , -0.43133 ,\n",
       "       -0.34311 ,  0.59789 , -0.58417 ,  0.068995,  0.23944 , -0.85181 ,\n",
       "        0.30379 , -0.34177 , -0.25746 , -0.031101, -0.16285 ,  0.45169 ,\n",
       "       -0.91627 ,  0.64521 ,  0.73281 , -0.22752 ,  0.30226 ,  0.044801,\n",
       "       -0.83741 ,  0.55006 , -0.52506 , -1.7357  ,  0.4751  , -0.70487 ,\n",
       "        0.056939, -0.7132  ,  0.089623,  0.41394 , -1.3363  , -0.61915 ,\n",
       "       -0.33089 , -0.52881 ,  0.16483 , -0.98878 ], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the word vector 'king'\n",
    "wiki_embeddings['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f26c7636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('princess', 0.7947245240211487),\n",
       " ('king', 0.7507690787315369),\n",
       " ('elizabeth', 0.7355712652206421),\n",
       " ('royal', 0.7065026760101318),\n",
       " ('lady', 0.7044796943664551),\n",
       " ('victoria', 0.6853758096694946),\n",
       " ('monarch', 0.6683257818222046),\n",
       " ('crown', 0.6680562496185303),\n",
       " ('prince', 0.6640505790710449),\n",
       " ('consort', 0.6570538282394409)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the word similar to king based on the trained word vectors\n",
    "\n",
    "wiki_embeddings.most_similar('queen')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d946fa4",
   "metadata": {},
   "source": [
    "### Train Our Own Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67c68bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data and clean up columns names\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78c86d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                  text  \n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...  \n",
       "1                                                                        Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
       "3                                                    U dun say so early hor... U c already then say...  \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = pd.read_csv('data/spam.csv', encoding='latin-1').drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)\n",
    "messages.columns = ['label', 'text']\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a931e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, only, in, bugis, great, world, la, buffet, cine, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>[free, entry, in, wkly, comp, to, win, fa, cup, final, tkts, st, may, text, fa, to, to, receive,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[dun, say, so, early, hor, already, then, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>[nah, don, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
       "1                                                                        Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "3                                                    U dun say so early hor... U c already then say...   \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "                                                                                            text_clean  \n",
       "0  [go, until, jurong, point, crazy, available, only, in, bugis, great, world, la, buffet, cine, th...  \n",
       "1                                                                          [ok, lar, joking, wif, oni]  \n",
       "2  [free, entry, in, wkly, comp, to, win, fa, cup, final, tkts, st, may, text, fa, to, to, receive,...  \n",
       "3                                                       [dun, say, so, early, hor, already, then, say]  \n",
       "4                                [nah, don, think, he, goes, to, usf, he, lives, around, here, though]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean data using the built in cleaner in gensim\n",
    "\n",
    "messages['text_clean'] = messages['text'].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01dc4fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(messages['text_clean'], messages['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "791fe6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the word2vec model\n",
    "w2v_model = gensim.models.Word2Vec(X_train,\n",
    "                                  size=100,\n",
    "                                  window=5,\n",
    "                                  min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af2b2622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0382229 , -0.08024513,  0.00363246, -0.00600205,  0.00704879,\n",
       "        0.00827206, -0.02581133, -0.02520023, -0.01668486, -0.00843029,\n",
       "        0.03472609, -0.01818832,  0.02245494, -0.03729883,  0.01100051,\n",
       "       -0.00573212, -0.03460041,  0.0910534 ,  0.030505  , -0.05989588,\n",
       "        0.00347106, -0.05961369, -0.06237208, -0.06955219,  0.01672626,\n",
       "        0.00273216,  0.01379673, -0.02019451, -0.04200555,  0.02316518,\n",
       "       -0.015997  , -0.06479035, -0.0141787 ,  0.02666479,  0.028094  ,\n",
       "       -0.04148806,  0.01400859, -0.00085329,  0.03799758,  0.02256233,\n",
       "        0.04087701,  0.03179458, -0.05219363, -0.00702705,  0.05379624,\n",
       "        0.01334256, -0.03127933, -0.0758174 , -0.05065704,  0.01773514,\n",
       "       -0.01881688, -0.02277704, -0.03768161,  0.04188111,  0.00352809,\n",
       "       -0.03256638,  0.04371538,  0.02179884, -0.01535647,  0.06309256,\n",
       "       -0.01528405, -0.01593807, -0.04690412,  0.00105966, -0.01214068,\n",
       "       -0.01989657,  0.00788707, -0.00904602,  0.01925175, -0.02136434,\n",
       "       -0.03538052, -0.01060358,  0.04686724, -0.05691373, -0.00084529,\n",
       "       -0.03113201, -0.04319654,  0.04417944, -0.03116787, -0.03807385,\n",
       "        0.00290238,  0.01133103, -0.01047197, -0.02625919, -0.05685315,\n",
       "        0.02862109,  0.00515563,  0.02449547,  0.06659142, -0.00185825,\n",
       "       -0.02122938, -0.02308806, -0.00681857,  0.0225362 ,  0.00678087,\n",
       "        0.02739333,  0.02761979, -0.02382634,  0.05437132,  0.07609605],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the word vector for 'king' base on our trained model\n",
    "w2v_model.wv['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f33e14db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('national', 0.9970955848693848),\n",
       " ('busy', 0.9970611333847046),\n",
       " ('ugh', 0.9970089793205261),\n",
       " ('able', 0.9969658255577087),\n",
       " ('again', 0.9969191551208496),\n",
       " ('both', 0.9969143867492676),\n",
       " ('eat', 0.9968969821929932),\n",
       " ('ok', 0.9968967437744141),\n",
       " ('now', 0.9968866109848022),\n",
       " ('after', 0.9968665242195129)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the most similar words to 'king' based on word vectors from our trained model\n",
    "w2v_model.wv.most_similar('king')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
