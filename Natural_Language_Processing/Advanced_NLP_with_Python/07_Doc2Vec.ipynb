{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doc2vec: How To Implement doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Our Own Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data, clean it, and then split into train and test sets\n",
    "import gensim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "messages = pd.read_csv('data/spam.csv', encoding='latin-1')\n",
    "messages = messages.drop(labels = [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis = 1)\n",
    "messages.columns = [\"label\", \"text\"]\n",
    "messages['text_clean'] = messages['text'].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(messages['text_clean'],\n",
    "                                                    messages['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tagged document objects to prepare to train the model\n",
    "tagged_docs = [gensim.models.doc2vec.TaggedDocument(v, [i]) for i, v in enumerate(X_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['that', 'was', 'random', 'saw', 'my', 'old', 'roomate', 'on', 'campus', 'he', 'graduated'], tags=[0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model = gensim.models.Doc2Vec(tagged_docs,\n",
    "                                 vector_size=100,\n",
    "                                 windows=5,\n",
    "                                 min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Parameter doc_words of infer_vector() must be a list of strings (not a single string).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-81bc935a6094>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# What happens if we pass in a single word like we did for word2vec?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0md2v_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py\u001b[0m in \u001b[0;36minfer_vector\u001b[1;34m(self, doc_words, alpha, min_alpha, epochs, steps)\u001b[0m\n\u001b[0;32m    660\u001b[0m         \"\"\"\n\u001b[0;32m    661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 662\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Parameter doc_words of infer_vector() must be a list of strings (not a single string).\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Parameter doc_words of infer_vector() must be a list of strings (not a single string)."
     ]
    }
   ],
   "source": [
    "# What happens if we pass in a single word like we did for word2vec?\n",
    "d2v_model.infer_vector('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.82526808e-03,  1.74581166e-02,  2.97803245e-03, -2.77172471e-03,\n",
       "        8.86322651e-03, -5.48810385e-05, -6.95343316e-03, -2.22267513e-03,\n",
       "       -1.01481155e-02,  6.60797069e-03,  4.30492172e-03, -7.28191203e-03,\n",
       "       -6.23196684e-05,  2.78894906e-03,  2.92887539e-03,  6.87831314e-03,\n",
       "       -4.33500390e-05, -1.13993036e-02, -7.37652648e-03,  1.56966150e-02,\n",
       "       -1.01694120e-02,  1.11296689e-02,  2.60656071e-03, -1.13946060e-02,\n",
       "       -7.91499205e-03, -1.43859480e-02,  7.64571084e-03, -5.16226655e-03,\n",
       "        6.85975282e-03,  8.81140213e-03, -9.69223306e-03,  5.33209322e-03,\n",
       "        1.12158656e-02, -1.18167195e-02, -1.04749491e-02, -2.31086323e-03,\n",
       "       -3.86486674e-04,  7.70778349e-03, -5.56398649e-04, -2.52087694e-03,\n",
       "        3.32778622e-03, -2.68855551e-03,  1.43595520e-04, -2.49194796e-03,\n",
       "       -5.57762850e-03, -1.48840866e-03, -2.09801341e-03,  6.49039913e-03,\n",
       "        2.11346988e-03,  7.25614931e-03,  6.62197173e-03, -1.00030666e-04,\n",
       "       -1.33679213e-03,  8.24671425e-03,  9.63411236e-04, -6.43175747e-03,\n",
       "        1.40509680e-02,  2.13764445e-03,  3.73648386e-03,  2.10699043e-03,\n",
       "        7.11569702e-03,  3.49404220e-03, -9.23382584e-03, -1.95843261e-03,\n",
       "       -9.27271415e-03, -1.69724245e-02,  2.56726448e-03,  1.75811735e-03,\n",
       "        1.63315434e-03,  5.45994844e-03, -1.02436086e-02,  7.15882983e-03,\n",
       "        4.63338383e-03, -6.84400322e-03, -1.08894631e-02, -3.93656082e-03,\n",
       "        1.76540914e-03, -3.76664731e-03, -6.15759799e-03, -1.33969262e-02,\n",
       "       -6.54419092e-03, -2.93064886e-03,  2.39617773e-03,  7.14646932e-03,\n",
       "        9.40137077e-04,  1.99202560e-02,  5.66971395e-03,  5.39084477e-03,\n",
       "       -3.53616226e-04,  1.73822499e-03,  2.44225911e-03,  3.72062856e-03,\n",
       "        9.60616209e-03, -8.48413818e-03, -4.74655395e-03, -3.61914816e-03,\n",
       "       -4.68348758e-03,  3.12753604e-03, -3.55878589e-03,  2.16719275e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What happens if we pass in a list of words?\n",
    "d2v_model.infer_vector(['i', 'am', 'learning', 'nlp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model = gensim.models.Doc2Vec(tagged_docs,\n",
    "                                 vector_size=50,\n",
    "                                 windows=2,\n",
    "                                 min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00296452,  0.02894574, -0.00745052, -0.00864003,  0.01007967,\n",
       "       -0.01062912, -0.01539788, -0.00327487, -0.01001702,  0.01678144,\n",
       "       -0.00248412, -0.01731892,  0.0018326 ,  0.00878652,  0.00344362,\n",
       "        0.00623209, -0.00595455, -0.02368065, -0.01878495,  0.00889379,\n",
       "       -0.00250143,  0.00969916,  0.01635539, -0.01773514, -0.00493307,\n",
       "       -0.02446362,  0.01539156, -0.01119128,  0.00635523,  0.0132355 ,\n",
       "       -0.00966775, -0.00234093,  0.00583289, -0.02275368, -0.02087563,\n",
       "       -0.01145303, -0.01321785,  0.00733278,  0.00770667,  0.00016397,\n",
       "        0.00800007,  0.00070424,  0.0007819 , -0.01400255, -0.0013655 ,\n",
       "       -0.00078306, -0.00443488,  0.00842773,  0.00736947,  0.01017965],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v_model.infer_vector(['convert', 'words', 'to', 'vectors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = [[d2v_model.infer_vector(sent)] for sent in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-2.0729704e-03, -6.4691850e-03, -1.8684139e-03,  1.0389567e-02,\n",
       "         7.4779866e-03, -7.3604500e-03, -4.2284656e-04, -8.1549278e-03,\n",
       "        -4.6093566e-03,  1.0678447e-02,  3.8808768e-04, -4.0849652e-03,\n",
       "         1.5640198e-03,  2.1818997e-03,  6.0801406e-04, -5.8116298e-03,\n",
       "        -4.4885799e-03, -5.8491011e-03, -6.2749777e-03,  8.1115626e-03,\n",
       "        -7.0912992e-03,  2.0241616e-03, -8.2910340e-03, -4.5347270e-03,\n",
       "         3.4581814e-03, -6.2706969e-03, -7.4026658e-04,  8.4361434e-03,\n",
       "        -4.0726448e-04, -1.2659746e-03, -1.1304950e-02,  3.2247468e-03,\n",
       "        -3.3312890e-04, -4.2283046e-03, -7.4520572e-03,  8.1755535e-04,\n",
       "         9.1329003e-03,  2.1721770e-03,  1.5687380e-03,  6.5280749e-03,\n",
       "         4.4210739e-03,  7.4667786e-03,  7.5880112e-03, -3.8894257e-03,\n",
       "        -1.0134230e-02, -5.3136647e-03, -5.9610326e-03,  1.6625905e-04,\n",
       "        -2.9663011e-04,  3.5608165e-05], dtype=float32)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What About Pre-trained Document Vectors?\n",
    "\n",
    "There are not as many options as there are for word vectors. There also is not an easy API to read these in like there is for `word2vec` so it is more time consuming.\n",
    "\n",
    "Pre-trained vectors from training on Wikipedia and Associated Press News can be found [here](https://github.com/jhlau/doc2vec). Feel free to explore on your own!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
