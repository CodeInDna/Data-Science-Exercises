{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Exercise - Putting it All Together\n",
    "\n",
    "In this last exercise, you'll write a full ETL pipeline for the GDP data. That means you'll extract the World Bank data, transform the data, and load the data all in one go. In other words, you'll want one Python script that can do the entire process.\n",
    "\n",
    "Why would you want to do this? Imagine working for a company that creates new data every day. As new data comes in, you'll want to write software that periodically and automatically extracts, transforms, and loads the data.\n",
    "\n",
    "To give you a sense for what this is like, you'll extract the GDP data one line at a time. You'll then transform that line of data and load the results into a SQLite database. The code in this exercise is somewhat tricky.\n",
    "\n",
    "Here is an explanation of how this Jupyter notebook is organized:\n",
    "1. The first cell connects to a SQLite database called worldbank.db and creates a table to hold the gdp data. You do not need to do anything in this code cell other than executing the cell.\n",
    "2. The second cell has a function called extract_line(). You don't need to do anything in this code cell either besides executing the cell. This function is a [Python generator](https://wiki.python.org/moin/Generators). You don't need to understand how this works in order to complete the exercise. Essentially, a generator is like a regular function except instead of a return statement, a generator has a yield statement. Generators allow you to use functions in a for loop. In essence, this function will allow you to read in a data file one line at a time, run a transformation on that row of data, and then move on to the next row in the file.\n",
    "3. The third cell contains a function called transform_indicator_data(). This function receives a line from the csv file and transforms the data in preparation for a load step.\n",
    "4. The fourth cell contains a function called load_indicator_data(), which loads the trasnformed data into the gdp table in the worldbank.db database.\n",
    "5. The fifth cell runs the ETL pipeilne\n",
    "6. The sixth cell runs a query against the database to make sure everything worked correctly.\n",
    "\n",
    "You'll need to modify the third and fourth cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to create a database and a table, called gdp, to hold the gdp data\n",
    "# You do not need to change anything in this code cell\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "# connect to the database\n",
    "# the database file will be worldbank.db\n",
    "# note that sqlite3 will create this database file if it does not exist already\n",
    "conn = sqlite3.connect('worldbank.db')\n",
    "\n",
    "# get a cursor\n",
    "cur = conn.cursor()\n",
    "\n",
    "# drop the test table in case it already exists\n",
    "cur.execute(\"DROP TABLE IF EXISTS gdp\")\n",
    "\n",
    "# create the test table including project_id as a primary key\n",
    "cur.execute(\"CREATE TABLE gdp (countryname TEXT, countrycode TEXT, year INTEGER, gdp REAL, PRIMARY KEY (countrycode, year));\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator for reading in one line at a time\n",
    "# generators are useful for data sets that are too large to fit in RAM\n",
    "# You do not need to change anything in this code cell\n",
    "def extract_lines(file):\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        yield line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill out the code wherever you find a TODO in this cell\n",
    "# This function has two inputs:\n",
    "#   data, which is a row of data from the gdp csv file\n",
    "#   colnames, which is a list of column names from the csv file\n",
    "# The output should be a list of [countryname, countrycode, year, gdp] values\n",
    "# In other words, the output would look like:\n",
    "# [[Aruba, ABW, 1994, 1.330168e+09], [Aruba, ABW, 1995, 1.320670e+09], ...]\n",
    "#\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "# transform the indicator data\n",
    "def transform_indicator_data(data, colnames):\n",
    "    \n",
    "    # get rid of quote marks\n",
    "    for i, datum in enumerate(data):\n",
    "        data[i] = datum.replace('\"','')\n",
    "    \n",
    "    # TODO: the data variable contains a list of data in the form [countryname, countrycode, 1960, 1961, 1962,...]\n",
    "    # since this is the format of the data in the csv file. Extract the countryname from the list \n",
    "    # and put the result in the country variable\n",
    "    country = data[0]\n",
    "    \n",
    "    # these are \"countryname\" values that are not actually countries\n",
    "    non_countries = ['World',\n",
    "     'High income',\n",
    "     'OECD members',\n",
    "     'Post-demographic dividend',\n",
    "     'IDA & IBRD total',\n",
    "     'Low & middle income',\n",
    "     'Middle income',\n",
    "     'IBRD only',\n",
    "     'East Asia & Pacific',\n",
    "     'Europe & Central Asia',\n",
    "     'North America',\n",
    "     'Upper middle income',\n",
    "     'Late-demographic dividend',\n",
    "     'European Union',\n",
    "     'East Asia & Pacific (excluding high income)',\n",
    "     'East Asia & Pacific (IDA & IBRD countries)',\n",
    "     'Euro area',\n",
    "     'Early-demographic dividend',\n",
    "     'Lower middle income',\n",
    "     'Latin America & Caribbean',\n",
    "     'Latin America & the Caribbean (IDA & IBRD countries)',\n",
    "     'Latin America & Caribbean (excluding high income)',\n",
    "     'Europe & Central Asia (IDA & IBRD countries)',\n",
    "     'Middle East & North Africa',\n",
    "     'Europe & Central Asia (excluding high income)',\n",
    "     'South Asia (IDA & IBRD)',\n",
    "     'South Asia',\n",
    "     'Arab World',\n",
    "     'IDA total',\n",
    "     'Sub-Saharan Africa',\n",
    "     'Sub-Saharan Africa (IDA & IBRD countries)',\n",
    "     'Sub-Saharan Africa (excluding high income)',\n",
    "     'Middle East & North Africa (excluding high income)',\n",
    "     'Middle East & North Africa (IDA & IBRD countries)',\n",
    "     'Central Europe and the Baltics',\n",
    "     'Pre-demographic dividend',\n",
    "     'IDA only',\n",
    "     'Least developed countries: UN classification',\n",
    "     'IDA blend',\n",
    "     'Fragile and conflict affected situations',\n",
    "     'Heavily indebted poor countries (HIPC)',\n",
    "     'Low income',\n",
    "     'Small states',\n",
    "     'Other small states',\n",
    "     'Not classified',\n",
    "     'Caribbean small states',\n",
    "     'Pacific island small states']\n",
    "    \n",
    "    if country not in non_countries:\n",
    "        data_array = np.array(data, ndmin=2)\n",
    "        data_array.reshape(1, 63)\n",
    "        df = pd.DataFrame(data_array, columns=colnames).replace('', np.nan)\n",
    "        df.drop(['\\n', 'Indicator Name', 'Indicator Code'], inplace=True, axis=1)\n",
    "\n",
    "        # Reshape the data sets so that they are in long format\n",
    "        df_melt = df.melt(id_vars=['Country Name', 'Country Code'], \n",
    "                            var_name='year', \n",
    "                            value_name='gdp')\n",
    "        \n",
    "        results = []\n",
    "        for index, row in df_melt.iterrows():\n",
    "            country, countrycode, year, gdp = row\n",
    "            if str(gdp) != 'nan':\n",
    "                results.append([country, countrycode, year, gdp])\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill out the code wherever you find a TODO in this cell\n",
    "# This function loads data into the gdp table of the worldbank.db database\n",
    "# The input is a list of data outputted from the transformation step that looks like this:\n",
    "# [[Aruba, ABW, 1994, 1.330168e+09], [Aruba, ABW, 1995, 1.320670e+09], ...]\n",
    "\n",
    "# The function does not return anything. Instead, the function iterates through the input and inserts each\n",
    "# value into the gdp data set.\n",
    "\n",
    "def load_indicator_data(results):\n",
    "    \n",
    "    # TODO: connect to the worldbank.db database using the sqlite3 library\n",
    "    conn = sqlite3.connect('worldbank.db')\n",
    "    \n",
    "    # TODO: create a cursor object\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    if results:\n",
    "        \n",
    "        # iterate through the results variable and insert each result into the gdp table\n",
    "        for result in results:\n",
    "            \n",
    "            # TODO: extract the countryname, countrycode, year, and gdp from each iteration\n",
    "            countryname, countrycode, year, gdp = result\n",
    "\n",
    "            # TODO: prepare a query to insert a countryname, countrycode, year, gdp value\n",
    "            sql_string = 'INSERT INTO gdp (countryname, countrycode, year, gdp) VALUES (\"{}\", \"{}\", {}, {});'.format(countryname, countrycode, year, gdp)\n",
    "\n",
    "            # connect to database and execute query\n",
    "            try:\n",
    "                cur.execute(sql_string)\n",
    "            # print out any errors (like if the primary key constraint is violated)\n",
    "            except Exception as e:\n",
    "                print('error occurred:', e, result)\n",
    "    \n",
    "    # commit changes and close the connection\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this code cell to run the ETL pipeline\n",
    "# You do not need to change anything in this cell\n",
    "with open('../data/gdp_data.csv') as f:\n",
    "    for line in extract_lines(f):\n",
    "        data = line.split(',')\n",
    "        if len(data) == 63:\n",
    "            if data[0] == '\"Country Name\"':\n",
    "                colnames = []\n",
    "                # get rid of quote marks\n",
    "                for i, datum in enumerate(data):\n",
    "                    colnames.append(datum.replace('\"',''))\n",
    "            else:\n",
    "                # transform and load the line of indicator data\n",
    "                results = transform_indicator_data(data, colnames)\n",
    "                load_indicator_data(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countryname</th>\n",
       "      <th>countrycode</th>\n",
       "      <th>year</th>\n",
       "      <th>gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>ABW</td>\n",
       "      <td>1994</td>\n",
       "      <td>1.330168e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>ABW</td>\n",
       "      <td>1995</td>\n",
       "      <td>1.320670e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>ABW</td>\n",
       "      <td>1996</td>\n",
       "      <td>1.379888e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>ABW</td>\n",
       "      <td>1997</td>\n",
       "      <td>1.531844e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>ABW</td>\n",
       "      <td>1998</td>\n",
       "      <td>1.665363e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8709</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.545177e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8710</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.589105e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8711</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.630467e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8712</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2016</td>\n",
       "      <td>1.661996e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8713</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2017</td>\n",
       "      <td>1.784582e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8714 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     countryname countrycode  year           gdp\n",
       "0          Aruba         ABW  1994  1.330168e+09\n",
       "1          Aruba         ABW  1995  1.320670e+09\n",
       "2          Aruba         ABW  1996  1.379888e+09\n",
       "3          Aruba         ABW  1997  1.531844e+09\n",
       "4          Aruba         ABW  1998  1.665363e+09\n",
       "...          ...         ...   ...           ...\n",
       "8709    Zimbabwe         ZWE  2013  1.545177e+10\n",
       "8710    Zimbabwe         ZWE  2014  1.589105e+10\n",
       "8711    Zimbabwe         ZWE  2015  1.630467e+10\n",
       "8712    Zimbabwe         ZWE  2016  1.661996e+10\n",
       "8713    Zimbabwe         ZWE  2017  1.784582e+10\n",
       "\n",
       "[8714 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute this code cell to output the values in the gdp table\n",
    "# You do not need to change anything in this cell\n",
    "\n",
    "# connect to the database\n",
    "# the database file will be worldbank.db\n",
    "# note that sqlite3 will create this database file if it does not exist already\n",
    "conn = sqlite3.connect('worldbank.db')\n",
    "\n",
    "# get a cursor\n",
    "cur = conn.cursor()\n",
    "\n",
    "# create the test table including project_id as a primary key\n",
    "df = pd.read_sql(\"SELECT * FROM gdp\", con=conn)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "ETL Pipelines involve extracting data from one source, which in this case was a csv file, then transforming the data into a more usable form, and finally loading the data somewhere else.\n",
    "\n",
    "The purpose of ETL pipelines is to make data more usable and accessible. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
